# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: CAU Meal Crawling - Update data # 워크플로우 이름 지정

on:
  schedule:
    - cron:  '*/5 * * * *' # 주기적으로 실행하기 위한 스케줄링 - cron 설정

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.x
      uses: actions/setup-python@v1
      with:
          python-version: '3.x'
          architecture: 'x64'
    - name: Setup Chromedriver
      uses: nanasess/setup-chromedriver@v1.0.1
    - name: Install dependencies
      run: |
        pip install google-cloud-core==2.3.2
        pip install google-cloud-firestore==2.10.0
        pip install google-cloud-storage==2.7.0
        pip install json5==0.9.6
        pip install jsonschema==4.16.0
        pip install selenium==3.141.0
        pip install ujson==5.4.0
    - name: Run Scraper with python
      run: |
        python "main.py"
    - name: Commits
      run: |
        git config --local user.email "hth3396@gmail.com"
        git config --local user.name "Meal_Crawling_Success" # 커밋에 포함될 이름
        git add news.json
        git commit -m "Auto - Update data with Crawling" # 커밋 메세지
    - name: Push
      uses: ad-m/github-push-action@master
      with:
        branch: 'main'
        github_token: $ 
